{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План выполнения:\n",
    "\n",
    "- 1. Открытие файла с данными и его изучение\n",
    "- 2. Разделение исходных данных на обучающую, валидационную и тестовую выборки.\n",
    "- 3. Исследование качества разных моделей с помощью изменения гиперпараметров. Краткое описание выводов.\n",
    "- 4. Проверка качества модели на тестовой выборке.\n",
    "- 5. Проверка моделей на вменяемость.\n",
    "\n",
    "# Описание данных:\n",
    "\n",
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. \n",
    "\n",
    "Наименования столбцов:\n",
    "- **сalls** — количество звонков,\n",
    "- **minutes** — суммарная длительность звонков в минутах,\n",
    "- **messages** — количество sms-сообщений,\n",
    "- **mb_used** — израсходованный интернет-трафик в Мб,\n",
    "- **is_ultra** — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключение библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка и изучение файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Проведение дополнительной проверки по обработке данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя в условии сказано что предобработку данных выполнять не требуется, для большей уверенности проведем небольшую проверку данных, **в которой нам необходимо будет проверить**:\n",
    "- **Отсутствие отрицательных значений** во всех столбцах\n",
    "- Действительно ли **столбец 'is_ultra' содержит только значения 0 и 1**\n",
    "- **Равны ли дробные части значений в столбцах 'calls' и 'minutes' нулю**, так как у нас установлен тип float64:\n",
    "    - *Если равны*, тогда просто приведем тип данных в этих столбцах к int64\n",
    "    - *Если не равны*, тогда округлим значения и приведем тип данных к int64.\n",
    "- Присутствуют ли **дубликаты** в нашем датасете\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отсутствуют отрицательные значения в датасете.\n",
      "\n",
      "Столбец \"is_ultra\" содержит только значения 0 и 1.\n",
      "\n",
      "Дробные части значений в столбце \"calls\" равны нулю.\n",
      "Столбец \"calls\" успешно приведен к типу - int64\n",
      "\n",
      "Дробные части значений в столбце \"messages\" равны нулю.\n",
      "Столбец \"messages\" успешно приведен к типу - int64\n",
      "\n",
      "Дубликаты в датасете отсутствуют.\n"
     ]
    }
   ],
   "source": [
    "if (df < 0).values.any() == True:\n",
    "    print('Присутствуют отрицательные значения в датасете.')\n",
    "else:\n",
    "    print('Отсутствуют отрицательные значения в датасете.')\n",
    "\n",
    "print('')\n",
    "\n",
    "if (all(df['is_ultra'].isin([0, 1]))) == True:\n",
    "    print('Столбец \"is_ultra\" содержит только значения 0 и 1.')\n",
    "else:\n",
    "    print('Столбец \"is_ultra\" содержит иные значения, помимо 0 и 1.')\n",
    "\n",
    "print('')\n",
    "\n",
    "if df['calls'].mod(1).sum() == 0:\n",
    "    print('Дробные части значений в столбце \"calls\" равны нулю.')\n",
    "    df['calls'] = df['calls'].astype('int64')\n",
    "    print('Столбец \"calls\" успешно приведен к типу -', df['calls'].dtype)\n",
    "else:\n",
    "    print('Дробные части значений в столбце \"calls\" неравны нулю.')\n",
    "\n",
    "print('') \n",
    "\n",
    "if df['messages'].mod(1).sum() == 0:\n",
    "    print('Дробные части значений в столбце \"messages\" равны нулю.')\n",
    "    df['messages'] = df['messages'].astype('int64')\n",
    "    print('Столбец \"messages\" успешно приведен к типу -', df['messages'].dtype)\n",
    "else:\n",
    "    print('Дробные части значений в столбце \"messages\" неравны нулю.')\n",
    "\n",
    "print('')\n",
    "\n",
    "if df.duplicated().sum() == 0:\n",
    "    print('Дубликаты в датасете отсутствуют.')\n",
    "else:\n",
    "    print('Присутствуют дубликаты в датасете.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем, что действительно **нашему датасету не требуется предобработка данных**, за исключением приведения к нужному типу данных некоторых столбцов. Соответственно, можем смело приступать к следующему этапу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Разделение данных на выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для разбивки датасета на обучающую/валидационную/тестовую выборки**, мы выполним следующие действия:\n",
    "- 1. Разобъем датасет на два датафрейма с признаками и целевым признаком (принадлежность к тарифной группе)\n",
    "- 2. Напишем функцию, которая на входе будет получать два созданных выше датафрейма, и на выходе разделит их на три выборки: обучающую/валидационную/тестовую.\n",
    "- 3. После этого, выведет на экран информацию о размере полученных выборок в % соотношении от исходного датасета, и долю абонентов \"Ультра\" в наших выборках, для проверки их сбалансированности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 11111\n",
    "x_par = df.drop(['is_ultra'], axis = 1)\n",
    "y_tar = df['is_ultra']\n",
    "\n",
    "def train_valid_test_splitter(x_par, y_tar):\n",
    "    \n",
    "    text_prints = ['обучающей', 'валидационной', 'тестовой', \n",
    "                   'исходном датасете', 'обучающей выборке', 'валидационной выборке', 'тестовой выборке']\n",
    "    \n",
    "    global x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_par, y_tar, test_size = 0.4, random_state=random_state)\n",
    "    x_valid, x_test, y_valid, y_test = train_test_split(x_valid, y_valid, test_size = 0.5, random_state = random_state)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_valid = scaler.transform(x_valid)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    samples = [x_train, x_valid, x_test, y_tar, y_train, y_valid, y_test]\n",
    "    \n",
    "    for count in range (0, 7):\n",
    "        if count < 3:\n",
    "            print('Размер ' + text_prints[count] + ' выборки в % от исходного датасета =', \n",
    "                  round(len(samples[count]) / len(df), 2) * 100, '%')\n",
    "        elif count >= 3:\n",
    "            print('Доля абонентов \"Ультра\" в ' + text_prints[count], \n",
    "                  round(len(samples[count][samples[count] == 1]) / len(samples[count]), 2) * 100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки в % от исходного датасета = 60.0 %\n",
      "Размер валидационной выборки в % от исходного датасета = 20.0 %\n",
      "Размер тестовой выборки в % от исходного датасета = 20.0 %\n",
      "Доля абонентов \"Ультра\" в исходном датасете 31.0 %\n",
      "Доля абонентов \"Ультра\" в обучающей выборке 30.0 %\n",
      "Доля абонентов \"Ультра\" в валидационной выборке 32.0 %\n",
      "Доля абонентов \"Ультра\" в тестовой выборке 31.0 %\n"
     ]
    }
   ],
   "source": [
    "train_valid_test_splitter(x_par, y_tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что **разбиение на выборки выполнено успешно.** Получили обучающую выборку в размере 60% от исходного датасета, и валидационную и тестовую выборки по 20%, соответственно, от исходного датасета.\n",
    "\n",
    "Также наблюдаем что **выборки получились сбалансированные**, доли абонентов тарифа \"Ультра\" во всех выборках составляют 30-32%, что является допустимым интервалом, учитывая что в исходном датасете данная доля составляла 31%.\n",
    "\n",
    "Теперь **приступим к выбору наиболее оптимальной модели**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Исследование моделей.\n",
    "\n",
    "Исследование моделей, будем проводить используя подбор гиперпараметров с помощью GridSearchCV. Сначала для каждой модели получим наиболее оптимальные гиперпараметры (включая проведение пятикратной кросс-валидации, и после этого сравним результаты каждой оптимальной модели друг с другом, для выбора наилучшей.\n",
    "\n",
    "Для этого, будем использовать такие модели как:\n",
    "\n",
    "- **Дерево решений** - DecisionTreeClassifier\n",
    "- **Логистическая регрессия** - LogisticRegression\n",
    "- **Случайный лес** - RandomForestClassifier\n",
    "- **Метод ближайших соседей** - KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Дерево решений.\n",
    "\n",
    "Введем следующие интервалы параметров для их тестирования с помощью GridSearchCV:\n",
    "- *max_depth* - от 1 до 20\n",
    "- *min_samples_leaf* - от 1 до 10\n",
    "- *min_samples_split* - от 2 до 10\n",
    "\n",
    "После этого сразу же обучим модель, используя полученные оптимальные параметры, выведем их и точность нашей модели по обучающей и валидационной выборке на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mОптимальные параметры для модели, полученные с помощью GridSearchCV:\u001b[0m\n",
      "Максимальная глубина дерева - 8\n",
      "Минимальное число объектов в листе - 9\n",
      "Минимальный размер сэмпла для сплита - 2\n",
      "Точность на обучающей выборке - 0.846\n",
      "Точность на валидационной выборке - 0.795\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'max_depth': range (1, 20),\n",
    "             'min_samples_leaf': range (1,10),\n",
    "             'min_samples_split': range (2,10,)}\n",
    "\n",
    "model = DecisionTreeClassifier(random_state = random_state)\n",
    "grid = GridSearchCV(model, parametrs, cv = 5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "tree_model = DecisionTreeClassifier(**grid.best_params_, random_state = random_state)\n",
    "tree_model.fit(x_train, y_train)\n",
    "tree_train_predictions = tree_model.predict(x_train)\n",
    "tree_valid_predictions = tree_model.predict(x_valid)\n",
    "tree_accuracy_train = (round(accuracy_score(y_train, tree_train_predictions), 3))\n",
    "tree_accuracy_valid = (round(accuracy_score(y_valid, tree_valid_predictions), 3))\n",
    "\n",
    "print('\\033[1m' + 'Оптимальные параметры для модели, полученные с помощью GridSearchCV:' + '\\033[0m')\n",
    "print('Максимальная глубина дерева -', grid.best_params_['max_depth'])\n",
    "print('Минимальное число объектов в листе -', grid.best_params_['min_samples_leaf'])\n",
    "print('Минимальный размер сэмпла для сплита -', grid.best_params_['min_samples_split'])\n",
    "print('Точность на обучающей выборке -', tree_accuracy_train)\n",
    "print('Точность на валидационной выборке -', tree_accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученная модель, построенная с помощью GridSearchCV, проходит по нашему порогу адекватности в 0.75. \n",
    "Переходим к следующей модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mОптимальные параметры для модели, полученные с помощью GridSearchCV:\u001b[0m\n",
      "Параметр регуляризации - 0.5\n",
      "Веса классов - None\n",
      "Масштаб точки пересечения - 0.5\n",
      "Используемый решатель - lbfgs\n",
      "Точность на обучающей выборке - 0.757\n",
      "Точность на валидационной выборке - 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 640 out of 640 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "             'intercept_scaling': [0.5, 1.0, 1.5, 2.0, ],\n",
    "             'class_weight': [None, 'balanced'],\n",
    "             'C': [0.5, 1, 1.5, 2]}\n",
    "\n",
    "model = LogisticRegression(random_state = random_state)\n",
    "grid = GridSearchCV(model, parametrs, scoring='accuracy', verbose=1, cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "logistic_model = LogisticRegression(**grid.best_params_, random_state = random_state)\n",
    "logistic_model.fit(x_train, y_train)\n",
    "logistic_train_predictions = logistic_model.predict(x_train)\n",
    "logistic_valid_predictions = logistic_model.predict(x_valid)\n",
    "logistic_accuracy_train = (round(accuracy_score(y_train, logistic_train_predictions), 3))\n",
    "logistic_accuracy_valid = (round(accuracy_score(y_valid, logistic_valid_predictions), 3))\n",
    "\n",
    "print('\\033[1m' + 'Оптимальные параметры для модели, полученные с помощью GridSearchCV:' + '\\033[0m')\n",
    "print('Параметр регуляризации -', grid.best_params_['C'])\n",
    "print('Веса классов -', grid.best_params_['class_weight'])\n",
    "print('Масштаб точки пересечения -', grid.best_params_['intercept_scaling'])\n",
    "print('Используемый решатель -', grid.best_params_['solver'])\n",
    "print('Точность на обучающей выборке -', logistic_accuracy_train)\n",
    "print('Точность на валидационной выборке -', logistic_accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии с параметрами, полученными через GridSearchCV, едва проходит порог адекватности в 0.75 даже на обучающей выборке, на валидационной выборке модель не прошла порог."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Случайный лес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mОптимальные параметры для модели, полученные с помощью GridSearchCV:\u001b[0m\n",
      "Максимальная глубина дерева - 6\n",
      "Количество деревьев - 4\n",
      "Минимальное число объектов в листе - 9\n",
      "Минимальный размер сэмпла для сплита - 2\n",
      "Точность на обучающей выборке - 0.822\n",
      "Точность на валидационной выборке - 0.782\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'max_depth': range (1, 10),\n",
    "             'min_samples_leaf': range (5,10),\n",
    "             'min_samples_split': range (2,5),\n",
    "             'n_estimators': range (1, 5)}\n",
    "\n",
    "model = RandomForestClassifier(random_state = random_state)\n",
    "grid = GridSearchCV(model, parametrs, cv = 5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "forest_model = RandomForestClassifier(**grid.best_params_, random_state = random_state)\n",
    "forest_model.fit(x_train, y_train)\n",
    "forest_train_predictions = forest_model.predict(x_train)\n",
    "forest_valid_predictions = forest_model.predict(x_valid)\n",
    "forest_accuracy_train = (round(accuracy_score(y_train, forest_train_predictions), 3))\n",
    "forest_accuracy_valid = (round(accuracy_score(y_valid, forest_valid_predictions), 3))\n",
    "\n",
    "print('\\033[1m' + 'Оптимальные параметры для модели, полученные с помощью GridSearchCV:' + '\\033[0m')\n",
    "print('Максимальная глубина дерева -', grid.best_params_['max_depth'])\n",
    "print('Количество деревьев -', grid.best_params_['n_estimators'])\n",
    "print('Минимальное число объектов в листе -', grid.best_params_['min_samples_leaf'])\n",
    "print('Минимальный размер сэмпла для сплита -', grid.best_params_['min_samples_split'])\n",
    "print('Точность на обучающей выборке -', forest_accuracy_train)\n",
    "print('Точность на валидационной выборке -', forest_accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса с параметрами GridSearchCV, на данный момент, показывает наилучший результат с точностью в 0.82 на обучающей выборке, и 0.782 на валидационной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Метод ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mОптимальные параметры для модели, полученные с помощью GridSearchCV:\u001b[0m\n",
      "Количество соседей - 16\n",
      "Метод расчета веса - distance\n",
      "Алгоритм - ball_tree\n",
      "Точность на обучающей выборке - 1.0\n",
      "Точность на валидационной выборке - 0.792\n"
     ]
    }
   ],
   "source": [
    "parametrs = {'n_neighbors': range(1, 20),\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "grid = GridSearchCV(model, parametrs, cv = 5)\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "neighbors_model = KNeighborsClassifier(**grid.best_params_)\n",
    "neighbors_model.fit(x_train, y_train)\n",
    "neighbors_train_predictions = neighbors_model.predict(x_train)\n",
    "neighbors_valid_predictions = neighbors_model.predict(x_valid)\n",
    "neighbors_accuracy_train = (round(accuracy_score(y_train, neighbors_train_predictions), 3))\n",
    "neighbors_accuracy_valid = (round(accuracy_score(y_valid, neighbors_valid_predictions), 3))\n",
    "\n",
    "print('\\033[1m' + 'Оптимальные параметры для модели, полученные с помощью GridSearchCV:' + '\\033[0m')\n",
    "print('Количество соседей -', grid.best_params_['n_neighbors'])\n",
    "print('Метод расчета веса -', grid.best_params_['weights'])\n",
    "print('Алгоритм -', grid.best_params_['algorithm'])\n",
    "print('Точность на обучающей выборке -', neighbors_accuracy_train)\n",
    "print('Точность на валидационной выборке -', neighbors_accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, построенная с помощью метода ближайших соседей на параметрах от GridSearchCV показывает хороший результат на обучающей выборке с точностью в 0.793, однако результат сильно ухудшается на валидационной выборке, и модель едва проходит порог адекватности.\n",
    "\n",
    "**Общие выводы по моделям:**\n",
    "Проверив четыре модели - дерево решений, логистическая регрессия, случайный лес, метод ближайших соседей, мы получили следующие результаты на валидационных и тестовых выборках:\n",
    "- **Дерево решений:**\n",
    "    - Точность на обучающей выборке: 0.846\n",
    "    - Точность на валидационной выборке: 0.793\n",
    "    \n",
    "    \n",
    "- **Логистическая регрессия:**\n",
    "    - Точность на обучающей выборке: 0.752\n",
    "    - Точность на валидационной выборке: 0.737\n",
    "    \n",
    "    \n",
    "- **Случайный лес:**\n",
    "    - Точность на обучающей выборке: 0.822\n",
    "    - Точность на валидационной выборке: 0.782\n",
    "    \n",
    "    \n",
    "- **Метод ближайших соседей:**\n",
    "    - Точность на обучающей выборке: 0.793\n",
    "    - Точность на валидационной выборке: 0.753\n",
    "\n",
    "\n",
    "- **Наилучший результат на валидационной выборке:** случайный лес с автоматическим подбором параметров с помощью GrisSearchCV.\n",
    "    \n",
    "Порог адекватности не прошла модель логистической регрессии, однако, так как её значение точности не намного меньше порога адекватности, мы включим эту модель для проверки на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Проверка моделей на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки моделей на тестовой выборке, напишем функцию, которая на входе будет получать список с полученными моделями, значениями точности на валидационных выборках, а также названия моделей. На выходе функция выведет на экран точность на тестовой выборке для каждой модели, разницу в точности между тестовой и валидационной выборкой, а также укажет на наилучший результат какой-либо модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [tree_model, logistic_model, forest_model, neighbors_model]\n",
    "models_valid_accuracy = [tree_accuracy_valid, logistic_accuracy_valid, forest_accuracy_valid, neighbors_accuracy_valid]\n",
    "model_names = ['Дерево решений',\n",
    "              'Логистическая регрессия',\n",
    "              'Случайный лес',\n",
    "              'Метод ближайших соседей']\n",
    "\n",
    "def model_testing(models, model_names):\n",
    "    model_name = 0\n",
    "    best_accuracy = 0\n",
    "    for model in models:\n",
    "        test_predictions = model.predict(x_test)\n",
    "        accuracy = (round(accuracy_score(y_test, test_predictions), 3))\n",
    "        print('\\033[1m' + model_names[model_name] + '\\033[0m')\n",
    "        print('Точность на тестовой выборке =', accuracy)\n",
    "        print('Разница в точности между тестовой и валидационной выборкой =', \n",
    "              round(accuracy - models_valid_accuracy[model_name], 3))\n",
    "        print('')\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_name = model_names[model_name]\n",
    "        model_name += 1\n",
    "    print('\\033[1m' + 'Наилучший результат показывает модель ' + \"'\" + best_model_name + \"'\" + ' с точностью -', best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mДерево решений\u001b[0m\n",
      "Точность на тестовой выборке = 0.776\n",
      "Разница в точности между тестовой и валидационной выборкой = -0.017\n",
      "\n",
      "\u001b[1mЛогистическая регрессия\u001b[0m\n",
      "Точность на тестовой выборке = 0.745\n",
      "Разница в точности между тестовой и валидационной выборкой = 0.008\n",
      "\n",
      "\u001b[1mСлучайный лес\u001b[0m\n",
      "Точность на тестовой выборке = 0.787\n",
      "Разница в точности между тестовой и валидационной выборкой = 0.005\n",
      "\n",
      "\u001b[1mМетод ближайших соседей\u001b[0m\n",
      "Точность на тестовой выборке = 0.753\n",
      "Разница в точности между тестовой и валидационной выборкой = 0.0\n",
      "\n",
      "\u001b[1mНаилучший результат показывает модель 'Случайный лес' с точностью - 0.787\n"
     ]
    }
   ],
   "source": [
    "model_testing(models, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью полученной функции, мы видим, что **наилучший результат всё же показала модель \"Случайный лес\"** с результатом на тестовой выборке в 0.787, что является допустим значением для нашего порога адекватности.\n",
    "\n",
    "**Модель логистической регрессии показала чуть более лучший результат** на тестовой выборке, однако всё же не проходит по нашему порогу адекватности, **занимая последнее место по точности.** \n",
    "\n",
    "**На третьем месте находится модель, построенная с помощью метода ближайших соседей**, с результатом в 0.753. \n",
    "\n",
    "**На втором месте находится модель дерева решений с точностью на тестовой выборке** в 0.776."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 384,
    "start_time": "2021-06-21T05:06:58.752Z"
   },
   {
    "duration": 520,
    "start_time": "2021-06-21T05:10:11.506Z"
   },
   {
    "duration": 729,
    "start_time": "2021-06-21T05:10:13.915Z"
   },
   {
    "duration": 584,
    "start_time": "2021-06-21T05:10:14.646Z"
   },
   {
    "duration": 27,
    "start_time": "2021-06-21T05:10:15.233Z"
   },
   {
    "duration": 50,
    "start_time": "2021-06-21T05:10:15.263Z"
   },
   {
    "duration": 24,
    "start_time": "2021-06-21T05:10:15.315Z"
   },
   {
    "duration": 12,
    "start_time": "2021-06-21T05:10:15.341Z"
   },
   {
    "duration": 11,
    "start_time": "2021-06-21T05:10:21.872Z"
   },
   {
    "duration": 670,
    "start_time": "2021-06-21T05:10:25.279Z"
   },
   {
    "duration": 5,
    "start_time": "2021-06-21T05:10:46.839Z"
   },
   {
    "duration": 29,
    "start_time": "2021-06-21T05:10:56.079Z"
   },
   {
    "duration": 49413,
    "start_time": "2021-06-21T05:11:00.632Z"
   },
   {
    "duration": 5069,
    "start_time": "2021-06-21T05:11:50.048Z"
   },
   {
    "duration": 28120,
    "start_time": "2021-06-21T05:11:55.120Z"
   },
   {
    "duration": 43207,
    "start_time": "2021-06-21T05:12:23.242Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "318.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
